{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os import path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from PyQt5 import QtCore\n",
    "from PyQt5 import QtWidgets\n",
    "from PyQt5 import QtGui\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pytesseract import image_to_string\n",
    "from gtts import gTTS\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "tessdata_config = r'--tessdata-dir \"C:\\Program Files\\Tesseract-OCR\\tessdata\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecordVideo(QtCore.QObject):\n",
    "    image_data = QtCore.pyqtSignal(np.ndarray)\n",
    "\n",
    "    def __init__(self, camera_port=0, parent=None):\n",
    "        super().__init__(parent)\n",
    "        self.camera = cv2.VideoCapture(camera_port)\n",
    "        \n",
    "        self.timer = QtCore.QBasicTimer()\n",
    "\n",
    "    def start_recoding(self):\n",
    "        self.timer.start(0, self)\n",
    "\n",
    "    def timerEvent(self, event):\n",
    "        if (event.timerId() != self.timer.timerId()):\n",
    "            return\n",
    "        read, data = self.camera.read()\n",
    "        if read:\n",
    "            self.image_data.emit(data)\n",
    "    \n",
    "    def saveframe(self):\n",
    "        read, data = self.camera.read()\n",
    "        if read:\n",
    "            cv2.imwrite(\"a.png\", data)\n",
    "            image = Image.fromarray(data)\n",
    "            image.load()\n",
    "\n",
    "            text = pytesseract.image_to_string(image, lang='eng', config=tessdata_config)\n",
    "            print('Text_Found:', text, len(text))\n",
    "\n",
    "            if len(text)>0:\n",
    "                text_to_speech = gTTS(text=text, lang='en')\n",
    "                text_to_speech.save('converteVoice.mp3')\n",
    "                os.system('start converteVoice.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for detection window\n",
    "class DetectionWidget(QtWidgets.QWidget):\n",
    "    def __init__(self, parent=None):\n",
    "        super().__init__(parent)\n",
    "        self.image = QtGui.QImage()\n",
    "        self._red = (0, 0, 255)\n",
    "        self._width = 2\n",
    "        self._min_size = (30, 30)\n",
    "\n",
    "    def image_data_slot(self, image_data):\n",
    "        self.image = self.get_qimage(image_data)\n",
    "        if self.image.size() != self.size():\n",
    "            self.setFixedSize(self.image.size())\n",
    "        self.update()\n",
    "\n",
    "    def get_qimage(self, image: np.ndarray):\n",
    "        height, width, color = image.shape\n",
    "        bytesPerLine = 3 * width\n",
    "        QImage = QtGui.QImage\n",
    "\n",
    "        image = QImage(\n",
    "            image.data,\n",
    "            width,\n",
    "            height,\n",
    "            bytesPerLine,\n",
    "            QImage.Format_RGB888\n",
    "        )\n",
    "\n",
    "        image = image.rgbSwapped()\n",
    "        return image\n",
    "    \n",
    "    def paintEvent(self, event):\n",
    "        painter = QtGui.QPainter(self)\n",
    "        painter.drawImage(0, 0, self.image)\n",
    "        self.image = QtGui.QImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FinalClass\n",
    "class MainWidget(QtWidgets.QWidget):\n",
    "    def __init__(self, parent=None):\n",
    "        super().__init__(parent)\n",
    "\n",
    "        self.detection_widget = DetectionWidget()\n",
    "        self.record_video = RecordVideo()\n",
    "\n",
    "        image_slot = self.detection_widget.image_data_slot\n",
    "        self.record_video.image_data.connect(image_slot)\n",
    "\n",
    "        layout = QtWidgets.QVBoxLayout()\n",
    "        layout.addWidget(self.detection_widget)\n",
    "        self.run_button = QtWidgets.QPushButton('Start')\n",
    "        layout.addWidget(self.run_button)\n",
    "        \n",
    "        self.run_button.clicked.connect(self.record_video.start_recoding)\n",
    "\n",
    "        self.screenshot = QtWidgets.QPushButton('snap shot')\n",
    "        layout.addWidget(self.screenshot)\n",
    "        self.screenshot.clicked.connect(self.record_video.saveframe)\n",
    "        self.setLayout(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    main_window = QtWidgets.QMainWindow()\n",
    "    main_widget = MainWidget()\n",
    "    main_window.setCentralWidget(main_widget)\n",
    "    main_window.show()\n",
    "\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
